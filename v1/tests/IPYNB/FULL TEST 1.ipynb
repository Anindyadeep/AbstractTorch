{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> (Activation Module) modules imported successfully ....\n",
      "=====> (Conv Module) modules imported successfully ....\n",
      "=====> (Dense Module) modules imported successfully ....\n",
      "=====> (Model Arch) modules imported successfully ....\n",
      "=====> (Training Metrics) modules imported successfully ....\n",
      "=====> (Train Eval Module) modules imported successfully ....\n",
      "=====> (Test Modules 1) modules imported successfully ....\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import sys \n",
    "    from pathlib import Path\n",
    "    BASE_DIR = \"/home/anindya/Documents/pytorch/abt/ABT/AbstractTorch/v1\" \n",
    "    sys.path.append(str(BASE_DIR))\n",
    "    from Architectures import model_arch as ma \n",
    "    from Training import train_eval as te \n",
    "    print(\"=====> (Test Modules 1) modules imported successfully ....\")\n",
    "except ModuleNotFoundError as e: \n",
    "    print(f\"ERROR: {e} Install modules properly ....\")\n",
    "\n",
    "\n",
    "import torch \n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST(\n",
    "            root = \"/home/anindya/Documents/pytorch/abt/ABT/AbstractTorch/v1/tests/test_data\",\n",
    "            download = True,\n",
    "            train = True,\n",
    "            transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = MNIST(\n",
    "            root = \"/home/anindya/Documents/pytorch/abt/ABT/AbstractTorch/v1/tests/test_data\",\n",
    "            download = True,\n",
    "            train = False,\n",
    "            transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAKING TORCH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = ma.TorchModel(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not flattened ... flattening the layer\n"
     ]
    }
   ],
   "source": [
    "torch_model.addConv2d(64, (3,3))\n",
    "torch_model.addConv2d(128, (3,3), activation=\"relu\")\n",
    "torch_model.addConv2d(128, (3,3), activation=\"relu\")\n",
    "torch_model.addDense(256, activation = \"relu\")\n",
    "torch_model.addDense(64, activation=\"relu\")\n",
    "torch_model.addDense(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    LAYERS                SUMMARY\n",
      "--  --------------------  -------------------------------------------------------------------\n",
      " 0  conv2d_layer_0        Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      " 1  conv2d_layer_1        Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      " 2  relu_within_conv2d_1  ReLU()\n",
      " 3  conv2d_layer_2        Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      " 4  relu_within_conv2d_2  ReLU()\n",
      " 5  flatten               Flatten(start_dim=1, end_dim=-1)\n",
      " 6  linear_layer_0        Linear(in_features=100352, out_features=256, bias=True)\n",
      " 7  relu_within_dense_0   ReLU()\n",
      " 8  linear_layer_1        Linear(in_features=256, out_features=64, bias=True)\n",
      " 9  relu_within_dense_1   ReLU()\n",
      "10  linear_layer_2        Linear(in_features=64, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(torch_model.arch_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    LAYERS            SUMMARY\n",
      "--  --------------  ---------\n",
      " 0  conv2d_layer_0       4096\n",
      " 1  conv2d_layer_1    4653056\n",
      " 2  conv2d_layer_2    9371648\n",
      " 3  linear_layer_0    6422528\n",
      " 4  linear_layer_1      16384\n",
      " 5  linear_layer_2       4096\n"
     ]
    }
   ],
   "source": [
    "print(torch_model.param_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_model.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING TORCH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "data_loaders = {\"train\": train_loader, \"valid\": valid_loader}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "num_epochs = 2\n",
    "task = \"classification\"\n",
    "save_checkpts_path = \"/home/anindya/Documents/pytorch/abt/ABT/AbstractTorch/v1/tests/chckpts\"\n",
    "early_stop = 1\n",
    "\n",
    "tt = te.TorchTrain(\n",
    "    data_loaders=data_loaders, \n",
    "    model = model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    schedular=scheduler, \n",
    "    num_epochs=num_epochs, \n",
    "    task=task, save_checkpoints_path=save_checkpts_path, early_stop=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started ....\n",
      "\n",
      "Epoch 0/1\n",
      "----------\n",
      "=====> train after_batch: 382.0 loss: [0.1083328127861023] acc: [0.984375] precision: [0.984375] recall: [0.984375] f1: [0.984375]]"
     ]
    }
   ],
   "source": [
    "model = tt.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
